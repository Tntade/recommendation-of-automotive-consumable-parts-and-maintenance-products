{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings,gc,os,time,math\n",
    "import pymysql\n",
    "warnings.filterwarnings('ignore')\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "filename='ud20201019'\n",
    "num='_34' \n",
    "today='20201023'\n",
    "\n",
    "datap='/home/jupyter/LQ/VW/data/'\n",
    "new_datap='/home/jupyter/LCG/dazhong/V2/%s/'%(filename) #读取阿桂的数据\n",
    "savep='/home/jupyter/LQ/VW/20191217_VW_下次保养里程预测/20201023自动化更新数据/%s%s/'%(today,str(num))\n",
    "\n",
    "if os.path.exists(savep):\n",
    "    print('True')\n",
    "else:\n",
    "    os.mkdir(savep)\n",
    "    \n",
    "s1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFromdb94(db,tablename,where_select):\n",
    "    dbconn=pymysql.connect(\n",
    "    host=\"192.168.1.94\",database=db,user=\"root\",password=\"Datauser@2017\",port=3306,charset='utf8')\n",
    "    sqlcmd=\"select * from \"+tablename+where_select\n",
    "    print(sqlcmd)\n",
    "    a=pd.read_sql(sqlcmd,dbconn)\n",
    "    return(a)\n",
    "\n",
    "def check_df(df):\n",
    "    df=df.drop_duplicates()\n",
    "    print(df.shape)\n",
    "    print(df[['VIN','修理日期']].drop_duplicates().shape)\n",
    "    print(df['VIN'].nunique())\n",
    "\n",
    "def check_run_time(s):\n",
    "    r=(time.time()-s)/60\n",
    "    return \"Run Mins: %f\"%r\n",
    "\n",
    "def get_car(df,old_name):\n",
    "    df[old_name]=df[old_name].apply(lambda x:str(x).lower())\n",
    "    pattern='辉昂|Phideon|phideon'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='辉昂'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='途昂|Teramont|teramont'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='途昂'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='帕萨特|Passat|passat|新领驭|领驭'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='帕萨特'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='途观|Tiguan|tiguan'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='途观'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='凌渡|Lamando|lamando'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='凌渡'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='朗行|朗逸|朗境|Lavida|lavida'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='朗逸'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='途安|Touran|touran'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='途安'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='Polo|polo|波罗'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='Polo'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='桑塔纳|Santana|santana'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='桑塔纳'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='途岳|tharu|Tharu'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='途岳'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    pattern='途铠|t-cross'\n",
    "    df.loc[df[old_name].str.contains(pattern),'一级车系']='途铠'\n",
    "    df.loc[df[old_name].str.contains('混'),'二级车系']='电动车'\n",
    "    df.loc[df['二级车系'].isnull(),'二级车系']='非电动车'\n",
    "    return df\n",
    "\n",
    "def get_car_family(df,new_name):\n",
    "    high=['辉昂','途昂']\n",
    "    mid_high=['帕萨特','帕萨特电动','途观','途观电动']\n",
    "    mid=['凌渡','朗逸','朗逸电动','途安','途岳']\n",
    "    low=['Polo','桑塔纳','途铠']\n",
    "    df.loc[df[new_name].isin(high),'车型档次']='高档'\n",
    "    df.loc[df[new_name].isin(mid_high),'车型档次']='中高档'\n",
    "    df.loc[df[new_name].isin(mid),'车型档次']='中低档'\n",
    "    df.loc[df[new_name].isin(low),'车型档次']='低档'\n",
    "    return df\n",
    "\n",
    "def get_revise_types(repare_maintain_info):\n",
    "    repare_maintain_info['修理类型']=repare_maintain_info['修理类型'].fillna('没有进店过')\n",
    "    pattern = r'常规保养|7500保养|定期保养|快速保养|普修有保养|润滑保养|维修保养|预约保养|A类保养|17保养|常保|快保|换油|更换机油'\n",
    "    repare_maintain_info.loc[repare_maintain_info['修理类型'].str.contains(pattern), u'常规保养'] = 1\n",
    "    repare_maintain_info.loc[repare_maintain_info['修理类型'] == '保养', u'常规保养'] = 1\n",
    "    pattern = r'质量担保保养|首次|首保|新帕.*首'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'首保'] = 1\n",
    "    pattern = r'附件安装|附件加装|附件销售'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'附件安装'] = 1\n",
    "    pattern = r'事故|中保'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'事故车维修'] = 1\n",
    "    pattern = r'一般|普通维修|普通修理|普修|预约修理|小修|延保维修|大客户修理|三包维修|定点修理空'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'一般维修'] = 1\n",
    "    pattern = r'索赔|理赔|受控|索'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'普通索赔'] = 1\n",
    "    pattern = r'活动|优惠维修|积分兑换|赠|厂家专项|免费检测|无费用'\n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains(pattern), u'服务活动'] = 1 \n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains('二手车认证维修'), u'二手车认证维修'] = 1 \n",
    "    repare_maintain_info.loc[repare_maintain_info[u'修理类型'].str.contains('内部车辆维修|内部修理'),u'内部车辆维修'] = 1 \n",
    "    return repare_maintain_info\n",
    "\n",
    "# (1)LSV\n",
    "# (2)第4位:车身型式\n",
    "# (3)第5位:变速器\n",
    "# (4)第6位:乘员保护系统\n",
    "# (5)第7/8位:车辆等级\n",
    "# # (6)第9位:检验位\n",
    "# (7)第10位:生产年份\n",
    "# (8)第11位:装配厂\n",
    "def get_user(df):\n",
    "    df['VIN']=df['VIN'].apply(str)\n",
    "    df['brand']=df['VIN'].apply(lambda x:str(x)[:3])\n",
    "    df['车身型式']=df['VIN'].apply(lambda x:x[3])\n",
    "    df['变速器']=df['VIN'].apply(lambda x:x[4])\n",
    "    df['乘员保护系统']=df['VIN'].apply(lambda x:x[5])\n",
    "    df['车辆等级']=df['VIN'].apply(lambda x:x[6:8])\n",
    "    df['生产年份']=df['VIN'].apply(lambda x:x[9])\n",
    "    df['装配厂']=df['VIN'].apply(lambda x:x[10])\n",
    "    for col in ['车身型式', '变速器', '乘员保护系统', '车辆等级', '生产年份', '装配厂']:\n",
    "        df[col]=df[col].astype(str)\n",
    "    df['用户属性']=list(map(lambda a,b,c,d,e,f:a+','+b+','+c+','+d+','+e+','+f,df['车身型式'],df['变速器'],\n",
    "                        df['乘员保护系统'],df['车辆等级'],df['生产年份'],df['装配厂']))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_miss_cols(df):\n",
    "    tt=pd.isnull(df).sum().reset_index()\n",
    "    tt.columns=['字段名','缺失值']\n",
    "    tt['缺失值占比']=tt['缺失值']/df.shape[0]\n",
    "    tt=tt.sort_values(by=['缺失值占比'],ascending=False).reset_index(drop=True)\n",
    "    miss_cols=tt[tt['缺失值占比']>0]['字段名'].unique().tolist()\n",
    "    miss_df=tt[tt['缺失值占比']>0]\n",
    "    return miss_cols,miss_df\n",
    "\n",
    "def check_every_col_value(df):\n",
    "    cols=list(df.columns)\n",
    "    cols.remove('VIN')\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        print(df[col].unique().tolist())\n",
    "        print('-'*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_veh_base_info(new_datap):\n",
    "    \n",
    "    print('############客户标签车辆基础数据############')\n",
    "    dd1=pd.read_pickle(new_datap+'%s_车辆基础数据%s.pickle'%(filename,num))\n",
    "    print('原始字段有: ',dd1.columns.tolist())\n",
    "    \n",
    "    needs=['VIN', '使用性质', '出厂日期', '发动机-机组号', '变速箱-机组号', '技术代码', '技术代码1',\n",
    "       '换购', '排量', '档位', '购车时间', '车型描述', '车型代码', '进气方式']\n",
    "    dd1=dd1[needs].drop_duplicates()\n",
    "    dd1['购车时间']=pd.to_datetime(dd1['购车时间'])\n",
    "    dd1=dd1.sort_values(by=['VIN','购车时间'],ascending=False).drop_duplicates(['VIN'],keep='last').reset_index(drop=True)\n",
    "    \n",
    "    dd1.loc[dd1['技术代码']=='0','技术代码']=np.nan\n",
    "    dd1.loc[dd1['排量']=='0','排量']=np.nan\n",
    "    dd1.loc[~(dd1['进气方式'].isin(['涡轮增压','自然吸气'])),'进气方式']=np.nan\n",
    "    dd1=dd1.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    cols=list(dd1.columns)\n",
    "    cols.remove('VIN')\n",
    "    for col in cols:\n",
    "        tmp=dd1[dd1[col].notnull()][['VIN',col]].drop_duplicates()\n",
    "        print(col)\n",
    "        print(tmp.shape)\n",
    "        print(tmp['VIN'].nunique())\n",
    "        print('-'*30)\n",
    "        del dd1[col]\n",
    "        dd1=dd1.merge(tmp,on=['VIN'],how='left')\n",
    "    dd1=dd1.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return dd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_member_info(new_datap):\n",
    "    \n",
    "    print('############会员_账户行为############')\n",
    "    dd2=pd.read_pickle(new_datap+'%s_会员信息%s.pickle'%(filename,num))\n",
    "    print('原始字段有: ',list(dd2.columns))\n",
    "        \n",
    "    if 'vin码' in dd2.columns.tolist():\n",
    "        dd2.rename(columns={'vin码':'VIN'},inplace=True)\n",
    "    cols=['VIN','会员卡生成时间', '会员卡类型', '会员卡状态', '性别','是否绑定微信']\n",
    "    dd2=dd2[cols].drop_duplicates()\n",
    "    dd2['会员卡生成时间']=pd.to_datetime(dd2['会员卡生成时间'])\n",
    "    dd2=dd2.sort_values(by=['VIN','会员卡生成时间'],ascending=False).drop_duplicates(['VIN'],keep='last').reset_index(drop=True)\n",
    "    dd2['会员卡年龄']=(pd.to_datetime(today)-dd2['会员卡生成时间']).apply(lambda x:math.ceil(x.days/180))\n",
    "    del dd2['会员卡生成时间']\n",
    "    dd2=dd2.drop_duplicates().reset_index(drop=True)\n",
    "    gender_dic2={'MALE':'男','FEMALE':'女','UNKNOWN':'未知'}\n",
    "    dd2['性别1']=dd2['性别'].map(gender_dic2)\n",
    "    del dd2['性别']\n",
    "    \n",
    "    cols=dd2.columns.tolist()\n",
    "    cols.remove('VIN')\n",
    "    for col in cols:\n",
    "        tmp=dd2[dd2[col].notnull()][['VIN',col]].drop_duplicates()\n",
    "        print(col)\n",
    "        print(tmp.shape)\n",
    "        print(tmp['VIN'].nunique())\n",
    "        print('-'*30)\n",
    "        del dd2[col]\n",
    "        dd2=dd2.merge(tmp,on=['VIN'],how='left')\n",
    "        \n",
    "    dd2=dd2.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cust_info(new_datap):\n",
    "    print('############客户标签车主基础数据############')\n",
    "    dd4=pd.read_pickle(new_datap+'%s_车主基础数据%s.pickle'%(filename,num))\n",
    "    print('原始字段有: ',dd4.columns.tolist())\n",
    "        \n",
    "    cols=['VIN','车主性质','性别','车辆类型']\n",
    "    dd4=dd4[cols].drop_duplicates()\n",
    "\n",
    "    gender_dic1={'男':'男','女':'女','没有回答':'未知'}\n",
    "    dd4['性别']=dd4['性别'].map(gender_dic1)\n",
    "    dd4.loc[dd4['车辆类型']=='nan','车辆类型']=np.nan\n",
    "\n",
    "    cols=dd4.columns.tolist()\n",
    "    cols.remove('VIN')\n",
    "    for col in cols:\n",
    "        tmp=dd4[dd4[col].notnull()][['VIN',col]].drop_duplicates()\n",
    "        print(col)\n",
    "        print(tmp.shape)\n",
    "        print(tmp['VIN'].nunique())\n",
    "        print('-'*30)\n",
    "        del dd4[col]\n",
    "        dd4=dd4.merge(tmp,on=['VIN'],how='left')\n",
    "\n",
    "    dd4=dd4.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return dd4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vehicle(new_datap):\n",
    "    dd1=get_veh_base_info(new_datap)\n",
    "    dd2=get_member_info(new_datap)\n",
    "    dd4=get_cust_info(new_datap)\n",
    "    \n",
    "    print('############合并,outer merge############')\n",
    "    veh=dd1.merge(dd2,on=['VIN'],how='outer').merge(dd4,on=['VIN'],how='outer')\n",
    "    veh.loc[veh['性别'].isnull(),'性别']=veh['性别1']\n",
    "    del veh['性别1']\n",
    "    \n",
    "    veh.loc[veh['技术代码'].isnull(),'技术代码']=veh['技术代码1']\n",
    "    del veh['技术代码1']\n",
    "    \n",
    "    veh=get_user(veh)\n",
    "    \n",
    "    veh['出厂日期']=pd.to_datetime(veh['出厂日期']).dt.normalize()  \n",
    "    veh['购车时间']=pd.to_datetime(veh['购车时间']).dt.normalize()  \n",
    "    \n",
    "    print('一级车系和二级车系和车型档次')\n",
    "    veh=get_car(veh,'车型描述') #一级车系,二级车系\n",
    "    veh=get_car_family(veh,'一级车系') #车型档次 \n",
    "    del veh['车型描述']\n",
    "    \n",
    "    veh=veh.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return veh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############客户标签车辆基础数据############\n",
      "原始字段有:  ['ID', 'NET_CODE', 'VIN', '使用性质', '出厂日期', '发动机-机组号', '变速箱-机组号', '品牌', '技术代码', '技术代码1', '换购', '排量', '档位', '维修车系', '维修车系年款', '购车时间', '购车经销商代码', '车型', '车型_EN', '车型代码', '车型年份', '车型描述', '车型级别', '车型颜色代码', '车牌号', '进气方式']\n",
      "使用性质\n",
      "(801479, 2)\n",
      "801479\n",
      "------------------------------\n",
      "出厂日期\n",
      "(850310, 2)\n",
      "850310\n",
      "------------------------------\n",
      "发动机-机组号\n",
      "(818548, 2)\n",
      "818548\n",
      "------------------------------\n",
      "变速箱-机组号\n",
      "(818548, 2)\n",
      "818548\n",
      "------------------------------\n",
      "技术代码\n",
      "(818038, 2)\n",
      "818038\n",
      "------------------------------\n",
      "技术代码1\n",
      "(803816, 2)\n",
      "803816\n",
      "------------------------------\n",
      "换购\n",
      "(850310, 2)\n",
      "850310\n",
      "------------------------------\n",
      "排量\n",
      "(818038, 2)\n",
      "818038\n",
      "------------------------------\n",
      "档位\n",
      "(818038, 2)\n",
      "818038\n",
      "------------------------------\n",
      "购车时间\n",
      "(850286, 2)\n",
      "850286\n",
      "------------------------------\n",
      "车型描述\n",
      "(850310, 2)\n",
      "850310\n",
      "------------------------------\n",
      "车型代码\n",
      "(850310, 2)\n",
      "850310\n",
      "------------------------------\n",
      "进气方式\n",
      "(818038, 2)\n",
      "818038\n",
      "------------------------------\n",
      "############会员_账户行为############\n",
      "原始字段有:  ['vin码', '卡id', '车主id', '会员卡号', '会员卡生成时间', '会员卡类型', '经销商', '会员卡状态', '性别', '可用积分', '微信id', '会员升降级日期', '最后一次积分时间', '维保累计用次数（1、2、3、0）', '积分积累金额', '积分消耗金额', '电子券累计获取次数', '电子券累计使用次数', '电子券累计抵扣积分', '是否绑定微信']\n",
      "会员卡类型\n",
      "(384179, 2)\n",
      "384179\n",
      "------------------------------\n",
      "会员卡状态\n",
      "(384179, 2)\n",
      "384179\n",
      "------------------------------\n",
      "是否绑定微信\n",
      "(384179, 2)\n",
      "384179\n",
      "------------------------------\n",
      "会员卡年龄\n",
      "(384179, 2)\n",
      "384179\n",
      "------------------------------\n",
      "性别1\n",
      "(382365, 2)\n",
      "382365\n",
      "------------------------------\n",
      "############客户标签车主基础数据############\n",
      "原始字段有:  ['ID', 'VIN', '姓名', '识别码', '车主性质', '证件类型', '身份证', '出生日期', '性别', '婚姻状态', '教育程度', '职业', '行业', '职位', '邮箱', '创建时间', '手机', '省份', '城市', '地址', '收入', '邮编', '车主类型补充', '车辆类型', 'interests', '职务', '送修人姓名', '送修人手机']\n",
      "车主性质\n",
      "(543225, 2)\n",
      "543225\n",
      "------------------------------\n",
      "性别\n",
      "(480996, 2)\n",
      "480996\n",
      "------------------------------\n",
      "车辆类型\n",
      "(525155, 2)\n",
      "525155\n",
      "------------------------------\n",
      "############合并,outer merge############\n",
      "一级车系和二级车系和车型档次\n",
      "(850310, 30)\n",
      "850310\n"
     ]
    }
   ],
   "source": [
    "vehicle=get_vehicle(new_datap)\n",
    "print(vehicle.shape)\n",
    "print(vehicle['VIN'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>2.处理主单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_day_revise_types(df):\n",
    "    def revise_type_merge(a,b,c,d,e,f,g,h,i):\n",
    "        lst=[]\n",
    "        if a==1:\n",
    "            lst.append('首保')\n",
    "        if b==1:\n",
    "            lst.append('常规保养')\n",
    "        if c==1:\n",
    "            lst.append('附件安装')\n",
    "        if d==1:\n",
    "            lst.append('一般维修')\n",
    "        if e==1:\n",
    "            lst.append('事故车维修')\n",
    "        if f==1:\n",
    "            lst.append('普通索赔')\n",
    "        if g==1:\n",
    "            lst.append('服务活动')\n",
    "        if h==1:\n",
    "            lst.append('二手车认证维修')\n",
    "        if i==1:\n",
    "            lst.append('内部车辆维修')\n",
    "        return ','.join(lst)\n",
    "\n",
    "    df['修理类型_new']=list(map(lambda a,b,c,d,e,f,g,h,i:revise_type_merge(a,b,c,d,e,f,g,h,i),\n",
    "                                 df['首保'],df['常规保养'],df['附件安装'],df['一般维修'],\n",
    "                                 df['事故车维修'],df['普通索赔'],df['服务活动'],\n",
    "                                 df['二手车认证维修'],df['内部车辆维修']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始字段有:  ['VIN', '交车日期', '交车时间', '修理日期', '修理时间', '修理类型', '公里数', '其他费用', '创建时间', '委托书号', '工时费', '年份', '总金额', '折前其他费用', '折前工时费', '折前总金额', '折前维修费', '折前零件费', '服务顾问', '牌照号', '索赔标记', '经销商代码', '结算单号', '维修费', '负结算标志', '送修人名称', '送修人电话', '零件费']\n",
      "(5470641, 20)\n",
      "(5149801, 2)\n",
      "804533\n",
      "1万公里的实际的最后一次保养数据也从这个zhudan_merged_org.csv表单中提取,一定要筛选出来保养数据!!!\n",
      "############提取匹配零件表单的数据,与新增的原生数据是不一样的匹配方式############\n",
      "#仅能匹配15selected中的零件数据,不能匹配新增数据!!!\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_pickle(new_datap+'%s_维修主单信息%s.pickle'%(filename,num))\n",
    "print('原始字段有: ',df1.columns.tolist())\n",
    "\n",
    "# needs=['VIN','公里数','经销商代码','结算单号','修理日期','修理类型',\n",
    "#        '维修费','折前维修费','工时费','零件费','车辆型号','委托书号']\n",
    "needs=['VIN','公里数','经销商代码','结算单号','修理日期','修理类型',\n",
    "       '维修费','折前维修费','工时费','零件费','委托书号']\n",
    "df1=df1[needs].drop_duplicates().reset_index(drop=True)\n",
    "df1.loc[df1['折前维修费'].isnull(),'折前维修费']=df1['维修费']\n",
    "df1['修理日期']=pd.to_datetime(df1['修理日期']).dt.normalize()\n",
    "df1['公里数']=df1['公里数'].astype(int).astype(float)\n",
    "df1['修理类型']=df1['修理类型'].apply(lambda x:str(x).replace(';',',').replace(' ',''))\n",
    "df1.rename(columns={'折前维修费':'维修金额_折前','维修费':'维修金额'},inplace=True)\n",
    "orders=['VIN','修理日期','公里数','修理类型',\n",
    "        '经销商代码','结算单号','委托书号','维修金额','维修金额_折前','工时费', '零件费']\n",
    "df1=df1[orders].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df1=df1.sort_values(by=['VIN','修理日期'],ascending=False).reset_index(drop=True)\n",
    "for col in ['维修金额','维修金额_折前','工时费', '零件费','公里数']:\n",
    "    df1[col]=df1[col].astype(float)\n",
    "df1=get_revise_types(df1)\n",
    "check_df(df1)\n",
    "\n",
    "print('1万公里的实际的最后一次保养数据也从这个zhudan_merged_org.csv表单中提取,一定要筛选出来保养数据!!!')\n",
    "df1.to_pickle(savep+'zhudan_merged_org.pkl')\n",
    "\n",
    "print(\"############提取匹配零件表单的数据,与新增的原生数据是不一样的匹配方式############\")\n",
    "zhudan_pipei1=df1[['VIN','修理日期','经销商代码','委托书号','结算单号']].drop_duplicates()\n",
    "tmp=df1[['VIN','修理日期','公里数']].drop_duplicates().groupby(['VIN','修理日期'])['公里数'].max().reset_index()\n",
    "zhudan_pipei1=zhudan_pipei1.merge(tmp,on=['VIN','修理日期'],how='left')\n",
    "print('#仅能匹配15selected中的零件数据,不能匹配新增数据!!!')\n",
    "zhudan_pipei1.to_pickle(savep+'zhudan_pipei_lingjian_15selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_shoubao(zhudan1):\n",
    "    print(\"####################清洗首保数据#####################\")\n",
    "    zhudan1=zhudan1.sort_values(by=['VIN','修理日期'],ascending=False).reset_index(drop=True)\n",
    "    feishoubao=zhudan1[zhudan1['首保']!=1]\n",
    "    shoubao=zhudan1[zhudan1['首保']==1]\n",
    "    tmp=shoubao.groupby('VIN')['修理日期'].nunique().reset_index(name='首保次数')\n",
    "    shoubao=shoubao.merge(tmp,on=['VIN'],how='left')\n",
    "    print('(1).有%d个VIN出现首保脏数据'%(shoubao[shoubao['首保次数']>=2]['VIN'].nunique()))\n",
    "\n",
    "    shoubao2=shoubao[shoubao['首保次数']==1]\n",
    "    shoubao1=shoubao[shoubao['首保次数']>=2]\n",
    "    shoubao1['时间差']=(shoubao1['修理日期']-shoubao1['购车时间']).apply(lambda x:x.days)\n",
    "    tmp=shoubao1.groupby('VIN')['时间差'].agg({'max','min'}).reset_index()\n",
    "    tmp['时间差1']=tmp['min']\n",
    "    tmp.loc[tmp['时间差1']<0,'时间差1']=tmp[tmp['时间差1']<0]['max']\n",
    "    tmp=tmp[['VIN','时间差1']].drop_duplicates()\n",
    "    shoubao1=shoubao1.merge(tmp,on=['VIN'],how='left')\n",
    "    shoubao1=shoubao1[shoubao1['时间差']==shoubao1['时间差1']].drop_duplicates().reset_index(drop=True)\n",
    "    print('(2).检查脏首保数据是否正确了:')\n",
    "    check_df(shoubao1)\n",
    "    del shoubao1['时间差']\n",
    "    del shoubao1['时间差1']\n",
    "    \n",
    "    print('(3).检查清洗以后的主单数据:')\n",
    "    zhudan2=pd.concat([shoubao1,shoubao2,feishoubao],axis=0)\n",
    "    del zhudan2['首保次数']\n",
    "    check_df(zhudan2)\n",
    "    \n",
    "    print('(4).检查首保:')\n",
    "    check=zhudan2[zhudan2['首保']==1]\n",
    "    check_df(check)\n",
    "\n",
    "    del zhudan1\n",
    "    del tmp\n",
    "    del shoubao\n",
    "    del feishoubao\n",
    "    del shoubao1\n",
    "    del shoubao2\n",
    "    del check\n",
    "    gc.collect()\n",
    "    \n",
    "    return zhudan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_zhudan(df,veh):\n",
    "    \n",
    "    def str_merge(lst):\n",
    "        nlst=[]\n",
    "        for i in lst:\n",
    "            ss=str(i).split(',')\n",
    "            for j in ss:\n",
    "                if j not in nlst:\n",
    "                    nlst.append(j)\n",
    "        return ','.join(nlst)\n",
    "    \n",
    "    print('################开始转换成vin+date的宽表################')\n",
    "    df['修理日期']=pd.to_datetime(df['修理日期']).dt.normalize()\n",
    "    zhudan=df.groupby(['VIN','修理日期']).agg({'公里数':'max','经销商代码':str_merge,\n",
    "                                           '修理类型':str_merge,'维修金额':'sum',\n",
    "                                           '维修金额_折前':'sum','工时费':'sum', '零件费':'sum'}).reset_index()\n",
    "    zhudan['brand']=zhudan['VIN'].apply(lambda x:str(x)[:3])\n",
    "    zhudan=get_revise_types(zhudan)\n",
    "    check_df(zhudan)\n",
    "    \n",
    "    print(\"########加入常去经销商########\")\n",
    "    changqu=df[['VIN','修理日期','经销商代码']].drop_duplicates().groupby(['VIN','经销商代码'])['经销商代码'].count().reset_index(name='次数')\n",
    "    changqu=changqu.sort_values(by=['VIN','次数'],ascending=False).drop_duplicates(subset=['VIN'],keep='first').drop_duplicates()\n",
    "    del changqu['次数']\n",
    "    changqu.rename(columns={'经销商代码':'常去经销商'},inplace=True)\n",
    "    print(changqu.shape)\n",
    "    print(changqu['VIN'].nunique())\n",
    "    zhudan=zhudan.merge(changqu,on=['VIN'],how='left')\n",
    "    \n",
    "    print('#############加入第一次进店时间##########')\n",
    "    first=df.sort_values(by=['VIN','修理日期'],ascending=False).drop_duplicates(['VIN'],keep='last').reset_index(drop=True)\n",
    "    first=first[['VIN','修理日期']].drop_duplicates().rename(columns={'修理日期':'第一次修理日期'})\n",
    "#     first['date']=(pd.to_datetime(first['修理日期'])).apply(lambda x:datetime.strftime(x,'%Y-%m')).apply(str)\n",
    "#     first['date']=first['date'].apply(lambda x:x+'-01').apply(str)\n",
    "#     first['date']=pd.to_datetime(first['date'])\n",
    "    changqu=changqu.merge(first,on=['VIN'],how='left')\n",
    "    \n",
    "    print('########加入购车时间########')\n",
    "    veh1=veh[['VIN','购车时间','出厂日期']].drop_duplicates().reset_index(drop=True)\n",
    "    zhudan1=zhudan.merge(veh1,on=['VIN'],how='left')\n",
    "    zhudan1['购车时间']=pd.to_datetime(zhudan1['购车时间'])\n",
    "    zhudan1['出厂日期']=pd.to_datetime(zhudan1['出厂日期'])\n",
    "    zhudan1['修理日期']=pd.to_datetime(zhudan1['修理日期'])\n",
    "\n",
    "    wrong_purchase_vin=zhudan1[zhudan1['修理日期']<zhudan1['购车时间']]\n",
    "    print('有多少vin出现了购车时间>修理日期:',wrong_purchase_vin['VIN'].nunique())\n",
    "    \n",
    "    gouche_weixiu=zhudan1[zhudan1['修理日期']==zhudan1['购车时间']]\n",
    "    print('有多少vin出现了购车那天就被记录了维修的:',gouche_weixiu['VIN'].nunique())\n",
    "    print('有多少记录出现了购车那天就被记录了维修的:',len(gouche_weixiu))\n",
    "    \n",
    "    zhudan1.loc[zhudan1['购车时间'].isnull(),'购车时间']=pd.to_datetime('1990-01-01')\n",
    "    zhudan1.loc[zhudan1['VIN'].isin(set(wrong_purchase_vin['VIN'])),'购车时间']=pd.to_datetime('1990-01-01')\n",
    "    \n",
    "    print('1.先用非空的出厂日期补缺')\n",
    "    zhudan1.loc[zhudan1['购车时间']==pd.to_datetime('1990-01-01'),'购车时间']=zhudan1[zhudan1['购车时间']==pd.to_datetime('1990-01-01')]['出厂日期']\n",
    "\n",
    "    print('2.再用大众规则中的生产年份补缺')\n",
    "    zhudan1['生产年份']=zhudan1['VIN'].apply(lambda x:x[9]).astype(str)\n",
    "\n",
    "    purchase_dic={'T':'1995-01-01', 'V':'1996-01-01', 'W':'1997-01-01','X':'1998-01-01',\n",
    "                  'Y':'1999-01-01','0':'2000-01-01','1':'2001-01-01','2':'2002-01-01',\n",
    "                  '3':'2003-01-01','4':'2004-01-01','5':'2005-01-01','6':'2006-01-01',\n",
    "                  '7':'2007-01-01','8':'2008-01-01','9':'2009-01-01',\n",
    "                  'A':'2010-01-01','B':'2011-01-01','C':'2012-01-01','D':'2013-01-01','E':'2014-01-01',\n",
    "                  'F':'2015-01-01','G':'2016-01-01','H':'2017-01-01','J':'2018-01-01','K':'2019-01-01',\n",
    "                  'L':'2020-01-01'}\n",
    "    zhudan1['生产年份1']=zhudan1['生产年份'].map(purchase_dic)\n",
    "    zhudan1['购车时间']=pd.to_datetime(zhudan1['购车时间'])\n",
    "    zhudan1['生产年份1']=pd.to_datetime(zhudan1['生产年份1'])\n",
    "    zhudan1.loc[(zhudan1['购车时间'].isnull())&(zhudan1['brand']=='LSV'),'购车时间']=zhudan1[(zhudan1['购车时间'].isnull())&(zhudan1['brand']=='LSV')]['生产年份1']\n",
    "\n",
    "    c1=zhudan1[zhudan1['购车时间'].isnull()]\n",
    "    print('还有多少VIN的购车时间是空置:',c1['VIN'].nunique())\n",
    "    \n",
    "    c2=zhudan1[zhudan1['修理日期']<zhudan1['购车时间']]\n",
    "    print('还有多少VIN的购车时间>修理日期:',c2['VIN'].nunique())\n",
    "    \n",
    "    print('3.用修理日期的最早时间补缺')\n",
    "    first=zhudan1.sort_values(by=['VIN','修理日期'],ascending=False).drop_duplicates(['VIN'],keep='last')\n",
    "    first=first[['VIN','修理日期']].drop_duplicates()\n",
    "    first['year']=(pd.to_datetime(first['修理日期'])).apply(lambda x:x.year).apply(str)\n",
    "    first['date']=first['year'].apply(lambda x:x+'-01-01').apply(str)\n",
    "    first['date']=pd.to_datetime(first['date'])\n",
    "    zhudan1=zhudan1.merge(first[['VIN','date']].drop_duplicates(),on='VIN',how='left')\n",
    "    \n",
    "    zhudan1.loc[zhudan1['购车时间'].isnull(),'购车时间']=zhudan1[zhudan1['购车时间'].isnull()]['date']\n",
    "    \n",
    "    vinlst=zhudan1[zhudan1['修理日期']<zhudan1['购车时间']]['VIN'].unique().tolist()\n",
    "    zhudan1.loc[zhudan1['VIN'].isin(vinlst),'购车时间']=zhudan1[zhudan1['VIN'].isin(vinlst)]['date']\n",
    "    \n",
    "    zhudan1['购车时间']=pd.to_datetime(zhudan1['购车时间'])\n",
    "    \n",
    "    c1=zhudan1[zhudan1['购车时间'].isnull()]\n",
    "    print('还有多少VIN的购车时间是空置:',c1['VIN'].nunique())\n",
    "    \n",
    "    c2=zhudan1[zhudan1['修理日期']<zhudan1['购车时间']]\n",
    "    print('还有多少VIN的购车时间>修理日期:',c2['VIN'].nunique())\n",
    "    \n",
    "    print('4.按理所有的购车时间都是小于修理日期的')\n",
    "    print(len(zhudan1[zhudan1['修理日期']==zhudan1['购车时间']]))\n",
    "    print(len(zhudan1[zhudan1['修理日期']>zhudan1['购车时间']]))\n",
    "    print(zhudan1.shape)\n",
    "    \n",
    "    print('5.去掉购车即维修的数据')\n",
    "    zhudan1=zhudan1.loc[zhudan1['修理日期']>zhudan1['购车时间']]\n",
    "    print(zhudan1.shape)\n",
    "\n",
    "    del zhudan1['出厂日期']\n",
    "    del zhudan1['生产年份']\n",
    "    del zhudan1['生产年份1']\n",
    "    del zhudan1['date']\n",
    "    \n",
    "    for col in ['首保','常规保养','附件安装','一般维修','事故车维修','普通索赔','服务活动',\n",
    "              '二手车认证维修','内部车辆维修']:\n",
    "        zhudan1[col]=zhudan1[col].fillna(0)\n",
    "        \n",
    "#     print('########加入一级二级车系########') \n",
    "#     veh2=veh[['VIN','一级车系','二级车系','车型档次']].drop_duplicates()\n",
    "#     zhudan1=zhudan1.merge(veh2,on=['VIN'],how='left')\n",
    "    \n",
    "    print(\"########清洗首保数据########\")\n",
    "    zhudan2=clear_shoubao(zhudan1)\n",
    "    \n",
    "#     print(\"#########加入首保经销商,可能涉及多个dealer1,dealer2#########\")\n",
    "#     tmp=zhudan2[zhudan2['首保']==1][['VIN','经销商代码']].rename(columns={'经销商代码':'首保经销商'})\n",
    "#     print(tmp.shape)\n",
    "#     print(tmp['VIN'].nunique())\n",
    "#     zhudan2=zhudan2.merge(tmp,on=['VIN'],how='left')\n",
    "\n",
    "    print(\"#########加入维修类型join#########\")\n",
    "    zhudan2=get_one_day_revise_types(zhudan2)\n",
    "    \n",
    "    new_buy=zhudan2[['VIN','购车时间']].drop_duplicates().rename(columns={'购车时间':'新购车时间'}).reset_index(drop=True)\n",
    "    print(new_buy.shape)\n",
    "    print(new_buy['VIN'].nunique())\n",
    "    \n",
    "    del c1\n",
    "    del c2\n",
    "    del wrong_purchase_vin\n",
    "    del zhudan1\n",
    "    del first\n",
    "    del veh1\n",
    "    del df\n",
    "    del zhudan\n",
    "    gc.collect()\n",
    "    \n",
    "    return zhudan2,changqu,new_buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################开始转换成vin+date的宽表################\n",
      "(5149801, 19)\n",
      "(5149801, 2)\n",
      "804533\n",
      "########加入常去经销商########\n",
      "(804533, 2)\n",
      "804533\n",
      "#############加入第一次进店时间##########\n",
      "########加入购车时间########\n",
      "有多少vin出现了购车时间>修理日期: 28623\n",
      "有多少vin出现了购车那天就被记录了维修的: 16001\n",
      "有多少记录出现了购车那天就被记录了维修的: 16001\n",
      "1.先用非空的出厂日期补缺\n",
      "2.再用大众规则中的生产年份补缺\n",
      "还有多少VIN的购车时间是空置: 0\n",
      "还有多少VIN的购车时间>修理日期: 4\n",
      "3.用修理日期的最早时间补缺\n",
      "还有多少VIN的购车时间是空置: 0\n",
      "还有多少VIN的购车时间>修理日期: 0\n",
      "4.按理所有的购车时间都是小于修理日期的\n",
      "12862\n",
      "5136939\n",
      "(5149801, 25)\n",
      "5.去掉购车即维修的数据\n",
      "(5136939, 25)\n",
      "########清洗首保数据########\n",
      "####################清洗首保数据#####################\n",
      "(1).有54个VIN出现首保脏数据\n",
      "(2).检查脏首保数据是否正确了:\n",
      "(54, 24)\n",
      "(54, 2)\n",
      "54\n",
      "(3).检查清洗以后的主单数据:\n",
      "(5136885, 21)\n",
      "(5136885, 2)\n",
      "804143\n",
      "(4).检查首保:\n",
      "(577953, 21)\n",
      "(577953, 2)\n",
      "577953\n",
      "#########加入维修类型join#########\n",
      "(804143, 2)\n",
      "804143\n"
     ]
    }
   ],
   "source": [
    "zhudan,changqu,new_buy=clear_zhudan(df1,vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136885, 22)\n",
      "(5136885, 2)\n",
      "804143\n"
     ]
    }
   ],
   "source": [
    "check_df(zhudan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Empty DataFrame\n",
      "Columns: [字段名, 缺失值, 缺失值占比]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "mis1,mis2=get_miss_cols(zhudan)\n",
    "print(mis1)\n",
    "print(mis2.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉事故车维修和普通索赔后,最后一次进店距离today,超过30*15天的为流失\n",
      "对于只有事故车或者索赔进店的人,如果购车时间距离today,超过30*15天的为流失\n",
      "适用于zhudan中所有VIN\n"
     ]
    }
   ],
   "source": [
    "print(\"去掉事故车维修和普通索赔后,最后一次进店距离today,超过30*15天的为流失\")\n",
    "print(\"对于只有事故车或者索赔进店的人,如果购车时间距离today,超过30*15天的为流失\")\n",
    "print('适用于zhudan中所有VIN')\n",
    "def get_instore_state(df,today):\n",
    "#     print('此处的df为zhudan所有数据!')\n",
    "    df.loc[(df['事故车维修']==1)|(df['普通索赔']==1),'流失不计算样本']=1\n",
    "    \n",
    "    buyuxia=df.loc[df['流失不计算样本']==1] #取出来的数据,所以可能与另外一部分出现重叠的情况\n",
    "    yuxia=df.loc[df['流失不计算样本']!=1]\n",
    "    \n",
    "    yuxia=yuxia.sort_values(by=['VIN','修理日期'],ascending=False).drop_duplicates(subset=['VIN'],keep='first').reset_index(drop=True)\n",
    "    yuxia=yuxia[['VIN','修理日期']].drop_duplicates()\n",
    "    yuxia['修理日期']=pd.to_datetime(yuxia['修理日期'])\n",
    "    yuxia['距今未进店天数']=(pd.to_datetime(today)-yuxia['修理日期']).apply(lambda x:x.days)\n",
    "    yuxia.loc[yuxia['距今未进店天数']>=30*15,'在店状态']='已流失'\n",
    "    yuxia.loc[yuxia['距今未进店天数']<30*15,'在店状态']='未流失'\n",
    "    \n",
    "    tmp=yuxia[['VIN','在店状态']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    other=df.loc[~(df['VIN'].isin(set(yuxia['VIN'])))][['VIN','购车时间']].drop_duplicates()\n",
    "    other['购车时间']=pd.to_datetime(other['购车时间'])\n",
    "    other['距今未进店天数']=(pd.to_datetime(today)-other['购车时间']).apply(lambda x:x.days)\n",
    "    other.loc[other['距今未进店天数']>=30*15,'在店状态']='只有事故索赔进店,已流失'\n",
    "    other.loc[other['距今未进店天数']<30*15,'在店状态']='只有事故索赔进店,未流失'\n",
    "\n",
    "    tmp1=other[['VIN','在店状态']].drop_duplicates().reset_index(drop=True)\n",
    "  \n",
    "    tmpp=pd.concat([tmp,tmp1],axis=0)\n",
    "\n",
    "    return tmpp\n",
    "\n",
    "\n",
    "def get_baoyang_state(df,today):\n",
    "#     print('此处的df为zhudan中保养数据!')\n",
    "    df.loc[(df['事故车维修']==1)|(df['普通索赔']==1),'流失不计算样本']=1\n",
    "    \n",
    "    buyuxia=df.loc[df['流失不计算样本']==1] #取出来的数据,所以可能与另外一部分出现重叠的情况\n",
    "    yuxia=df.loc[df['流失不计算样本']!=1]\n",
    "    \n",
    "    yuxia=yuxia.sort_values(by=['VIN','修理日期'],ascending=False).drop_duplicates(subset=['VIN'],keep='first').reset_index(drop=True)\n",
    "    yuxia=yuxia[['VIN','修理日期']].drop_duplicates()\n",
    "    yuxia['修理日期']=pd.to_datetime(yuxia['修理日期'])\n",
    "    yuxia['距今未进店天数']=(pd.to_datetime(today)-yuxia['修理日期']).apply(lambda x:x.days)\n",
    "    yuxia.loc[yuxia['距今未进店天数']>=30*15,'保养状态']='已流失'\n",
    "    yuxia.loc[yuxia['距今未进店天数']<30*15,'保养状态']='未流失'\n",
    "    \n",
    "    tmp=yuxia[['VIN','保养状态']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    other=df.loc[~(df['VIN'].isin(set(yuxia['VIN'])))][['VIN','购车时间']].drop_duplicates()\n",
    "    other['保养状态']='仅随事故或索赔才保养'\n",
    "    tmp1=other[['VIN','保养状态']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmpp=pd.concat([tmp,tmp1],axis=0)\n",
    "\n",
    "    return tmpp\n",
    "\n",
    "\n",
    "def get_vin_state(zhudan2,today):\n",
    "    print('##########在店状态##########')\n",
    "    instore_df=get_instore_state(zhudan2,today)\n",
    "    zhudan2=zhudan2.merge(instore_df,on=['VIN'],how='left')\n",
    "    \n",
    "    print('##########保养状态##########')\n",
    "    baoyang_zhudan=zhudan2[(zhudan2['首保']==1)|(zhudan2['常规保养']==1)]\n",
    "    instore_df1=get_baoyang_state(baoyang_zhudan,today)\n",
    "    zhudan2=zhudan2.merge(instore_df1,on=['VIN'],how='left')\n",
    "    zhudan2['保养状态']=zhudan2['保养状态'].fillna('没有保养记录')\n",
    "    \n",
    "    print('##########检查二个状态是否有缺失##########')\n",
    "    print(pd.isnull(zhudan2[['VIN','在店状态','保养状态']]).sum())\n",
    "    \n",
    "    zhudan_vin=zhudan2['VIN'].nunique()\n",
    "    \n",
    "    print('##########在店状态分布##########')\n",
    "    tmpp=zhudan2.groupby('在店状态')['VIN'].nunique().reset_index(name='人数')\n",
    "    tmpp['占比']=tmpp['人数']/zhudan_vin\n",
    "    print(tmpp.head())\n",
    "    \n",
    "    print('##########保养状态分布##########')\n",
    "    tmpp=zhudan2.groupby('保养状态')['VIN'].nunique().reset_index(name='人数')\n",
    "    tmpp['占比']=tmpp['人数']/zhudan_vin\n",
    "    print(tmpp.head())\n",
    "\n",
    "    return zhudan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########在店状态##########\n",
      "##########保养状态##########\n",
      "##########检查二个状态是否有缺失##########\n",
      "VIN     0\n",
      "在店状态    0\n",
      "保养状态    0\n",
      "dtype: int64\n",
      "##########在店状态分布##########\n",
      "           在店状态      人数        占比\n",
      "0  只有事故索赔进店,已流失   15857  0.019719\n",
      "1  只有事故索赔进店,未流失    2548  0.003169\n",
      "2           已流失  397902  0.494815\n",
      "3           未流失  387836  0.482297\n",
      "##########保养状态分布##########\n",
      "         保养状态      人数        占比\n",
      "0  仅随事故或索赔才保养    3131  0.003894\n",
      "1         已流失  420580  0.523016\n",
      "2         未流失  328276  0.408231\n",
      "3      没有保养记录   52156  0.064859\n"
     ]
    }
   ],
   "source": [
    "zhudan1=get_vin_state(zhudan,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_run(df):\n",
    "    df['修理日期']=pd.to_datetime(df['修理日期'])\n",
    "    df['购车时间']=pd.to_datetime(df['购车时间'])\n",
    "    df=df.sort_values(by=['VIN','修理日期'],ascending=False).reset_index(drop=True)\n",
    "    df['修理日期_last']=df.groupby('VIN')['修理日期'].shift(-1)\n",
    "    df['公里数_last']=df.groupby('VIN')['公里数'].shift(-1)\n",
    "    df.loc[df['修理日期_last'].isnull(),'修理日期_last']=df['购车时间']\n",
    "    df.loc[df['公里数_last'].isnull(),'公里数_last']=0\n",
    "    df['天数差']=(df['修理日期']-df['修理日期_last']).apply(lambda x:x.days)\n",
    "    df['公里数差']=(df['公里数']-df['公里数_last'])\n",
    "    df['日均差']=df['公里数差']/df['天数差']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baoyang_date_clean(baoyang):\n",
    "    baoyang=get_last_run(baoyang)\n",
    "\n",
    "    baoyang=baoyang.loc[baoyang['天数差']>7]\n",
    "    \n",
    "    tmp=baoyang.groupby('VIN')['修理日期'].nunique().reset_index(name='进店次数')\n",
    "    baoyang=baoyang.merge(tmp,on=['VIN'],how='left')\n",
    "\n",
    "    choose1=baoyang.loc[baoyang['进店次数']==1]\n",
    "    choose11=choose1[choose1['天数差']>7]\n",
    "\n",
    "    choose2=baoyang.loc[baoyang['进店次数']==2]\n",
    "    tmp=choose2.groupby('VIN')['天数差'].mean().reset_index(name='保养习惯')\n",
    "    choose2=choose2.merge(tmp,on=['VIN'],how='left')\n",
    "    choose2['保养习惯左']=choose2['保养习惯']*0.5\n",
    "    choose22=choose2.loc[choose2['天数差']>=choose2['保养习惯左']]\n",
    "\n",
    "    choose3=baoyang.loc[baoyang['进店次数']>=3]\n",
    "    choose33=choose3[choose3['天数差']>14]\n",
    "\n",
    "    baoyang=pd.concat([choose11,choose22,choose33],axis=0)\n",
    "    \n",
    "    baoyang=get_last_run(baoyang)\n",
    "\n",
    "    if '历史保养次数' in baoyang.columns.tolist():\n",
    "        del baoyang['历史保养数据']\n",
    "    if '保养次数' in baoyang.columns.tolist():\n",
    "        del baoyang['保养数据']\n",
    "    tmp=baoyang.groupby('VIN')['修理日期'].nunique().reset_index(name='历史保养次数')\n",
    "    baoyang=baoyang.merge(tmp,on=['VIN'],how='left')\n",
    "\n",
    "    return baoyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baoyang_data(zhudan1):\n",
    "\n",
    "    baoyang=zhudan1[(zhudan1['首保']==1)|(zhudan1['常规保养']==1)]\n",
    "    nobaoyang=zhudan1[~(zhudan1['VIN'].isin(set(baoyang['VIN'])))]\n",
    "    print(baoyang['VIN'].nunique()+nobaoyang['VIN'].nunique()==zhudan1['VIN'].nunique())\n",
    "    \n",
    "    print('##############提取baoyang_model###############')\n",
    "\n",
    "    print('1.保养数据清洗')\n",
    "    baoyang_model=baoyang_date_clean(baoyang)\n",
    "    check_df(baoyang_model)\n",
    "    print('历史保养次数最大值:',baoyang_model['历史保养次数'].max())\n",
    "    \n",
    "    print('2.去掉公里数差脏VIN')\n",
    "    check=baoyang_model[baoyang_model['公里数差']<=0]\n",
    "    print('其中公里数差有脏数据的VIN有:',check['VIN'].nunique())\n",
    "\n",
    "    baoyang_model=baoyang_model.loc[~(baoyang_model['VIN'].isin(set(check['VIN'])))]\n",
    "    cols=['保养习惯', '保养习惯左','进店次数']\n",
    "    baoyang_model=baoyang_model.drop(cols,axis=1)\n",
    "\n",
    "    print('3.取出有首保的人群,得到的数据分布是:')\n",
    "    shoubao=baoyang_model[baoyang_model['首保']==1]\n",
    "    baoyang_model=baoyang_model[baoyang_model['VIN'].isin(set(shoubao['VIN']))]\n",
    "    \n",
    "    print('4.最后检查baoyang_model数据:')\n",
    "    print('天数差最小值:',baoyang_model['天数差'].min())\n",
    "    print('公里数差最小值:',baoyang_model['公里数差'].min())\n",
    "    baoyang_model=baoyang_model.drop(['流失不计算样本','修理日期_last',\n",
    "                                        '公里数_last', '公里数差','天数差','日均差'],axis=1)\n",
    "    baoyang_model=baoyang_model.drop_duplicates().reset_index(drop=True)\n",
    "    check_df(baoyang_model)\n",
    "    \n",
    "    print('##############提取baoyang_rule###############')\n",
    "    baoyang_rule=baoyang[~(baoyang['VIN'].isin(set(baoyang_model['VIN'])))]\n",
    "    baoyang_rule_df=baoyang_date_clean(baoyang_rule)\n",
    "    print('天数差最小值:',baoyang_rule_df['天数差'].min())\n",
    "    print('公里数差最小值:',baoyang_rule_df['公里数差'].min())\n",
    "    baoyang_rule_df=baoyang_rule_df.drop(['流失不计算样本','修理日期_last',\n",
    "                                        '公里数_last', '公里数差','天数差','日均差',\n",
    "                                         '保养习惯', '保养习惯左','进店次数'],axis=1)\n",
    "    baoyang_rule_df=baoyang_rule_df.drop_duplicates().reset_index(drop=True)\n",
    "    check_df(baoyang_rule_df)\n",
    "    print('历史保养次数最大值:',baoyang_rule_df['历史保养次数'].max())\n",
    "    \n",
    "    nobaoyang1=baoyang_rule[~(baoyang_rule['VIN'].isin(set(baoyang_rule_df['VIN'])))] #放入规则中的,被清洗掉的人\n",
    "    nobaoyang1['首保']=0\n",
    "    nobaoyang1['常规保养']=0\n",
    "    print(zhudan1['VIN'].nunique()==baoyang_model['VIN'].nunique()+baoyang_rule_df['VIN'].nunique()+nobaoyang['VIN'].nunique()+nobaoyang1['VIN'].nunique())\n",
    "\n",
    "    print('##############提取nobaoyang###############')\n",
    "    nobaoyang=pd.concat([nobaoyang,nobaoyang1],axis=0)\n",
    "    check_df(nobaoyang)\n",
    "    \n",
    "    print(zhudan1['VIN'].nunique()==baoyang_model['VIN'].nunique()+baoyang_rule_df['VIN'].nunique()+nobaoyang['VIN'].nunique())\n",
    "    \n",
    "    return nobaoyang,baoyang_model,baoyang_rule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "##############提取baoyang_model###############\n",
      "1.保养数据清洗\n",
      "(3055155, 34)\n",
      "(3055155, 2)\n",
      "751441\n",
      "历史保养次数最大值: 85\n",
      "2.去掉公里数差脏VIN\n",
      "其中公里数差有脏数据的VIN有: 10566\n",
      "3.取出有首保的人群,得到的数据分布是:\n",
      "4.最后检查baoyang_model数据:\n",
      "天数差最小值: 8\n",
      "公里数差最小值: 1.0\n",
      "(2032856, 25)\n",
      "(2032856, 2)\n",
      "549622\n",
      "##############提取baoyang_rule###############\n",
      "天数差最小值: 8\n",
      "公里数差最小值: -494274.0\n",
      "(1022299, 25)\n",
      "(1022299, 2)\n",
      "201819\n",
      "历史保养次数最大值: 85\n",
      "True\n",
      "##############提取nobaoyang###############\n",
      "(119099, 25)\n",
      "(119099, 2)\n",
      "52702\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nobaoyang,baoyang_model,baoyang_rule=get_baoyang_data(zhudan1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549622\n",
      "549622\n",
      "201819\n",
      "201819\n",
      "52702\n",
      "52702\n"
     ]
    }
   ],
   "source": [
    "baoyang_model_fin=baoyang_model[baoyang_model['修理日期']>=pd.to_datetime('2014-01-01')]\n",
    "print(baoyang_model_fin['VIN'].nunique())\n",
    "print(baoyang_model['VIN'].nunique())\n",
    "\n",
    "baoyang_rule_fin=baoyang_rule[baoyang_rule['修理日期']>=pd.to_datetime('2014-01-01')]\n",
    "print(baoyang_rule_fin['VIN'].nunique())\n",
    "print(baoyang_rule['VIN'].nunique())\n",
    "\n",
    "nobaoyang_fin=nobaoyang[nobaoyang['修理日期']>=pd.to_datetime('2014-01-01')]\n",
    "print(nobaoyang_fin['VIN'].nunique())\n",
    "print(nobaoyang['VIN'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############分别对每个batch数据清洗,然后合并,重新生成新的主单数据,再加入预测人群分类#############\n",
      "['VIN', 'brand', '一般维修', '事故车维修', '二手车认证维修', '修理日期', '修理类型', '公里数', '内部车辆维修', '工时费', '常去经销商', '常规保养', '普通索赔', '服务活动', '经销商代码', '维修金额', '维修金额_折前', '购车时间', '附件安装', '零件费', '首保', '修理类型_new', '流失不计算样本', '在店状态', '保养状态', '人群_一级分类']\n",
      "(119099, 25)\n",
      "(119099, 2)\n",
      "52702\n",
      "['VIN', 'brand', '一般维修', '事故车维修', '二手车认证维修', '保养状态', '修理日期', '修理类型', '修理类型_new', '公里数', '内部车辆维修', '在店状态', '工时费', '常去经销商', '常规保养', '普通索赔', '服务活动', '经销商代码', '维修金额', '维修金额_折前', '购车时间', '附件安装', '零件费', '首保', '历史保养次数', '人群_一级分类']\n",
      "(2032856, 26)\n",
      "(2032856, 2)\n",
      "549622\n",
      "------------------------------\n",
      "['VIN', 'brand', '一般维修', '事故车维修', '二手车认证维修', '保养状态', '修理日期', '修理类型', '修理类型_new', '公里数', '内部车辆维修', '在店状态', '工时费', '常去经销商', '常规保养', '普通索赔', '服务活动', '经销商代码', '维修金额', '维修金额_折前', '购车时间', '附件安装', '零件费', '首保', '历史保养次数', '人群_一级分类']\n",
      "(1022299, 26)\n",
      "(1022299, 2)\n",
      "201819\n"
     ]
    }
   ],
   "source": [
    "print('############分别对每个batch数据清洗,然后合并,重新生成新的主单数据,再加入预测人群分类#############')\n",
    "nobaoyang_fin['人群_一级分类']='没有保养记录'\n",
    "print(nobaoyang_fin.columns.tolist())\n",
    "check_df(nobaoyang)\n",
    "\n",
    "baoyang_model_fin['人群_一级分类']='有保养记录,模型'\n",
    "print(list(baoyang_model_fin.columns))\n",
    "check_df(baoyang_model_fin)\n",
    "print('-'*30)\n",
    "\n",
    "baoyang_rule_fin['人群_一级分类']='有保养记录,规则'\n",
    "print(baoyang_rule_fin.columns.tolist())\n",
    "check_df(baoyang_rule_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新合成主单,数据情况如下:\n",
      "25\n",
      "['VIN', 'brand', '一般维修', '事故车维修', '二手车认证维修', '保养状态', '修理日期', '修理类型', '修理类型_new', '公里数', '内部车辆维修', '在店状态', '工时费', '常去经销商', '常规保养', '普通索赔', '服务活动', '经销商代码', '维修金额', '维修金额_折前', '购车时间', '附件安装', '零件费', '首保', '人群_一级分类']\n",
      "(3174254, 25)\n",
      "(3174254, 2)\n",
      "804143\n"
     ]
    }
   ],
   "source": [
    "print('重新合成主单,数据情况如下:')\n",
    "same_cols=[x for x in [y for y in baoyang_model_fin.columns.tolist() if y in baoyang_rule_fin.columns.tolist()] if x in nobaoyang_fin.columns.tolist()]\n",
    "print(len(same_cols))\n",
    "print(same_cols)\n",
    "\n",
    "fin_zhudan=pd.concat([nobaoyang_fin[same_cols],baoyang_model_fin[same_cols],baoyang_rule_fin[same_cols]],axis=0)\n",
    "fin_zhudan=fin_zhudan.drop_duplicates().reset_index(drop=True)\n",
    "check_df(fin_zhudan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fenlei(dff,today):\n",
    "    print('分类针对的是zhudan所有人,且这个zhudan是最终被清洗好以后的数据')\n",
    "    \n",
    "    dff=dff.sort_values(by=['VIN','修理日期'],ascending=False).reset_index(drop=True)\n",
    "    dff['修理日期']=pd.to_datetime(dff['修理日期'])\n",
    "    dff['购车时间']=pd.to_datetime(dff['购车时间'])\n",
    "    \n",
    "    dff['车龄']=(pd.to_datetime(today)-dff['购车时间']).apply(lambda x:x.days)\n",
    "    dff['车龄bin']=dff['车龄'].apply(lambda x:math.ceil(x/180))\n",
    "    \n",
    "    if '常规次数' in list(dff.columns):\n",
    "        del dff['常规次数']\n",
    "    tmp=dff[dff['首保']!=1]\n",
    "    tmp=tmp[tmp['常规保养']==1]\n",
    "    tmpp=tmp.groupby('VIN')['修理日期'].nunique().reset_index(name='常规次数')\n",
    "    dff=dff.merge(tmpp,on=['VIN'],how='left')\n",
    "    \n",
    "    if '首保次数' in list(dff.columns):\n",
    "        del dff['首保次数']\n",
    "    tmp=dff[dff['首保']==1]\n",
    "    tmp['首保次数']=1\n",
    "    dff=dff.merge(tmp[['VIN','首保次数']].drop_duplicates(),on=['VIN'],how='left')\n",
    "\n",
    "    for col in ['首保次数','常规次数']:\n",
    "        dff[col]=dff[col].fillna(0)\n",
    "\n",
    "    dff.loc[(dff['首保次数']==1)&(dff['常规次数']==0),'人群_二级分类']='有首保,无常规,预测第1次常规'\n",
    "    dff.loc[(dff['首保次数']==1)&(dff['常规次数']==1),'人群_二级分类']='有首保,1常规,预测第2次常规'\n",
    "    dff.loc[(dff['首保次数']==1)&(dff['常规次数']==2),'人群_二级分类']='有首保,2次常规,预测第3次常规'\n",
    "    dff.loc[(dff['首保次数']==1)&(dff['常规次数']>=3),'人群_二级分类']='3次及以上常规,预测接下去常规'\n",
    "    dff.loc[(dff['首保次数']==0)&(dff['常规次数']==1),'人群_二级分类']='无首保,1次常规,预测第2次常规(购车)'\n",
    "    dff.loc[(dff['首保次数']==0)&(dff['常规次数']==2),'人群_二级分类']='无首保,2次常规,预测第3次常规'\n",
    "    dff.loc[(dff['首保次数']==0)&(dff['常规次数']>=3),'人群_二级分类']='3次及以上常规,预测接下去常规'\n",
    "    dff.loc[(dff['首保次数']==0)&(dff['常规次数']==0)&(dff['车龄bin']<=3),'人群_二级分类']='无保养记录,预测首保'\n",
    "    dff.loc[(dff['首保次数']==0)&(dff['常规次数']==0)&(dff['车龄bin']>3),'人群_二级分类']='无保养习惯'\n",
    "\n",
    "    print('查看是否存在没有被分配到的人群')\n",
    "    c=dff[['VIN','人群_二级分类']].drop_duplicates().reset_index(drop=True)\n",
    "    print(c.shape)\n",
    "    print(c['VIN'].nunique())\n",
    "    print(pd.isnull(c).sum())\n",
    "    \n",
    "    print('查看对应的每一类人群的VIN数量')\n",
    "    tmp=dff.groupby('人群_二级分类')['VIN'].nunique().reset_index(name='人数')\n",
    "    print(tmp.head(10))\n",
    "    print(tmp['人数'].sum(0))\n",
    "    print(dff['VIN'].nunique())\n",
    "    \n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类针对的是zhudan所有人,且这个zhudan是最终被清洗好以后的数据\n",
      "查看是否存在没有被分配到的人群\n",
      "(804143, 2)\n",
      "804143\n",
      "VIN        0\n",
      "人群_二级分类    0\n",
      "dtype: int64\n",
      "查看对应的每一类人群的VIN数量\n",
      "                人群_二级分类      人数\n",
      "0       3次及以上常规,预测接下去常规  348534\n",
      "1                 无保养习惯   47094\n",
      "2            无保养记录,预测首保    5608\n",
      "3  无首保,1次常规,预测第2次常规(购车)   62805\n",
      "4      无首保,2次常规,预测第3次常规   10192\n",
      "5       有首保,1常规,预测第2次常规   79081\n",
      "6      有首保,2次常规,预测第3次常规   72926\n",
      "7       有首保,无常规,预测第1次常规  177903\n",
      "804143\n",
      "804143\n"
     ]
    }
   ],
   "source": [
    "fin_zhudan_df=fenlei(fin_zhudan,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_zhudan_df.to_pickle(savep+'final_zhudan.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "baoyang_model_fin=baoyang_model_fin.merge(fin_zhudan_df[['VIN','人群_二级分类']].drop_duplicates(),on=['VIN'],how='left')\n",
    "baoyang_model_fin.to_pickle(savep+'final_baoyang.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仅为6个固定字段,补充缺失值\n"
     ]
    }
   ],
   "source": [
    "print(\"仅为6个固定字段,补充缺失值\")\n",
    "def fill_missing(df,by_col,car_rel):\n",
    "\n",
    "    if '发动机组号' not in list(df.columns):\n",
    "        df.rename(columns={'发动机-机组号':'发动机组号'},inplace=True)\n",
    "    if '变速箱机组号' not in list(df.columns):\n",
    "        df.rename(columns={'变速箱-机组号':'变速箱机组号'},inplace=True)\n",
    "        \n",
    "    del_col=[]\n",
    "    for col in car_rel:\n",
    "        tmp=df.groupby([by_col,col])['VIN'].nunique().reset_index(name='人数')\n",
    "        tmp=tmp.sort_values(by=[by_col,'人数'],ascending=False).drop_duplicates(subset=[by_col],keep='first').reset_index(drop=True)\n",
    "        del tmp['人数']\n",
    "        tmp.columns=[by_col,'%s_众数'%col]\n",
    "        df=df.merge(tmp,on=[by_col],how='left')\n",
    "        df.loc[df[col].isnull(),col]=df['%s_众数'%col]\n",
    "        df.loc[df[col]=='nan',col]=df['%s_众数'%col]\n",
    "        del_col.append('%s_众数'%col)\n",
    "        gc.collect()\n",
    "    df1=df.drop(del_col,axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vehicle(datap,vehicle,changqu,new_buy,fin_zhudan_df):\n",
    "    vehicle=vehicle.merge(changqu,on=['VIN'],how='outer')\n",
    "    vehicle=vehicle.merge(new_buy,on=['VIN'],how='left')\n",
    "    print('1.检查vin数量')\n",
    "    print(vehicle.shape)\n",
    "    print(vehicle['VIN'].nunique())\n",
    "    \n",
    "    print('2.去掉又没有进店数据又没有购车时间的')\n",
    "    vehicle.loc[vehicle['购车时间'].isnull(),'购车时间']=vehicle['出厂日期']\n",
    "    vehicle.loc[(vehicle['购车时间'].isnull())&(vehicle['第一次修理日期'].notnull()),'购车时间']=vehicle[(vehicle['购车时间'].isnull())&(vehicle['第一次修理日期'].notnull())]['第一次修理日期'].apply(lambda x:pd.to_datetime(x)-relativedelta(days=7))\n",
    "\n",
    "    no_veh=vehicle[(vehicle['购车时间'].isnull())&(vehicle['常去经销商'].isnull())]\n",
    "    print(no_veh.shape)\n",
    "    print(no_veh['VIN'].nunique())\n",
    "    \n",
    "    vehicle=vehicle[~(vehicle['VIN'].isin(set(no_veh['VIN'])))]\n",
    "    \n",
    "    print('3.检查最终vin人数:')\n",
    "    print(vehicle.shape)\n",
    "    print(vehicle['VIN'].nunique())\n",
    "    \n",
    "    print('4.加入分类情况:')\n",
    "    tmp=fin_zhudan_df[['VIN','在店状态','保养状态','人群_一级分类','人群_二级分类']].drop_duplicates()\n",
    "    print(tmp.shape)\n",
    "    print(tmp['VIN'].nunique())\n",
    "    \n",
    "    vehicle=vehicle.merge(tmp,on=['VIN'],how='left')\n",
    "    \n",
    "    for col in ['在店状态','保养状态','人群_一级分类','人群_二级分类']:\n",
    "        vehicle[col]=vehicle[col].fillna('仅在2014年1月1日前进店过,已流失')\n",
    "    \n",
    "    vehicle=get_user(vehicle)\n",
    "    \n",
    "    print(\"##########################开始补充缺失值#########################\")\n",
    "    \n",
    "    print('1.一级车系和车型档次')\n",
    "    car_dic1={'一级车系':'途观','车型档次':'中高档'}\n",
    "    car_dic2={'一级车系':'朗逸','车型档次':'中低档'}\n",
    "    car_mode=vehicle['一级车系'].mode()[0]\n",
    "    if car_mode==car_dic1['一级车系']:\n",
    "        vehicle['一级车系']=vehicle['一级车系'].fillna(car_dic1['一级车系'])\n",
    "        vehicle['二级车系']=vehicle['二级车系'].fillna('非电动车')\n",
    "        vehicle['车型档次']=vehicle['车型档次'].fillna(car_dic1['车型档次'])\n",
    "    elif car_mode==car_dic2['一级车系']:\n",
    "        vehicle['一级车系']=vehicle['一级车系'].fillna(car_dic2['一级车系'])\n",
    "        vehicle['二级车系']=vehicle['二级车系'].fillna('非电动车')\n",
    "        vehicle['车型档次']=vehicle['车型档次'].fillna(car_dic2['车型档次'])\n",
    "        \n",
    "    print('2.vin相关属性')\n",
    "    fill_dic={'性别':'未知','会员卡类型':'NO_CARD','会员卡状态':3,'会员卡年龄':0,'是否绑定微信':0,\n",
    "              '换购':0,'车辆类型':'私家车','使用性质':'非营运','车主性质':'PERSONAL'}\n",
    "    for col in fill_dic:\n",
    "        vehicle[col]=vehicle[col].fillna(fill_dic[col])\n",
    "    \n",
    "    print('3.车型代码')\n",
    "    tmp=vehicle.groupby(['一级车系','车型代码'])['VIN'].nunique().reset_index(name='cnt')\n",
    "    tmp=tmp.sort_values(by=['一级车系','cnt'],ascending=False).drop_duplicates(['一级车系'],keep='first')\n",
    "    del tmp['cnt']\n",
    "    tmp=tmp.rename(columns={'车型代码':'车型代码众数'})\n",
    "    vehicle=vehicle.merge(tmp,on=['一级车系'],how='left')\n",
    "    vehicle.loc[vehicle['车型代码'].isnull(),'车型代码']=vehicle['车型代码众数']\n",
    "    del vehicle['车型代码众数']\n",
    "    \n",
    "    print('4.车子相关属性')\n",
    "    car_rel=['排量', '进气方式', '档位', '技术代码', '发动机组号', '变速箱机组号']\n",
    "    vehicle=fill_missing(vehicle,'车型代码',car_rel)\n",
    "    vehicle=fill_missing(vehicle,'一级车系',car_rel)\n",
    "    \n",
    "    print('########################匹配常去经销商的省份\\城市\\城市级别信息###############')\n",
    "    dealer=pd.read_excel(datap+'VW经销商信息20200513.xls',encoding='gbk')\n",
    "    cols=['省份', '城市','经销商代码']\n",
    "    dealer=dealer[cols].drop_duplicates().reset_index(drop=True)\n",
    "    dealer=dealer[dealer['经销商代码'].notnull()]\n",
    "    dealer['经销商代码']=dealer['经销商代码'].astype(int).astype(str)\n",
    "    dealer.rename(columns={'经销商代码':'常去经销商'},inplace=True)\n",
    "    dealer['城市']=dealer['城市'].apply(lambda x:str(x).replace('市',''))\n",
    "    dic2={'黔南布依族苗族自治州':'黔南', '恩施土家族苗族自治州':'恩施', '湘西土家族苗族自治州':'湘西',\n",
    "      '黔西南布依族苗族自治州':'黔西南', '喀什地区':'喀什', '阿克苏地区':'阿克苏',\n",
    "      '大理白族自治州':'大理', '黔东南苗族侗族自治州':'黔东南', '凉山彝族自治州':'凉山',\n",
    "      '楚雄彝族自治州':'楚雄', '西双版纳傣族自治州':'西双版纳', '文山壮族苗族自治州':'文山',\n",
    "      '海西蒙古族藏族自治州':'海西', '巴音郭楞蒙古自治州':'巴音郭楞', '德宏傣族景颇族自治州':'德宏',\n",
    "      '伊犁哈萨克自治州':'伊犁哈萨克', '昌吉回族自治州':'昌吉', '红河哈尼族彝族自治州':'红河',\n",
    "      '延边朝鲜族自治州':'延边', '阿拉善盟':'阿拉善', '兴安盟':'大兴安岭'}\n",
    "    dealer['城市']=dealer['城市'].apply(lambda x:dic2[x] if x in dic2 else x)\n",
    "    \n",
    "    vehicle['常去经销商']=vehicle['常去经销商'].fillna(1111111)\n",
    "    vehicle['常去经销商']=vehicle['常去经销商'].astype(int).astype(str)\n",
    "    vehicle=vehicle.merge(dealer,on=['常去经销商'],how='left')\n",
    "    vehicle.loc[vehicle['常去经销商']=='1111111','常去经销商']=np.nan\n",
    "\n",
    "    city=pd.read_excel(datap+'province_city_info.xlsx',encoding='gbk')\n",
    "    cols=['city', 'city_class']\n",
    "    city=city[cols].drop_duplicates().reset_index(drop=True)\n",
    "    city.columns=['城市','城市级别']\n",
    "    dic1={'大兴安岭': '大兴安岭', '延边州': '延边', '大理州': '大理', '文山州': '文山', '德宏州': '德宏',\n",
    "      '楚雄州': '楚雄', '红河州': '红河', '西双版纳州': '西双版纳', '喀什': '喀什', '巴音郭楞州': '巴音郭楞',\n",
    "      '昌吉州': '昌吉', '阿克苏': '阿克苏', '伊犁哈萨克州': '伊犁哈萨克', '黔西南州': '黔西南',\n",
    "      '黔东南州': '黔东南', '黔南州': '黔南', '凉山州': '凉山', '恩施州': '恩施', '湘西州': '湘西',\n",
    "      '海西族州': '海西', '阿拉善': '阿拉善'}\n",
    "    city['城市']=city['城市'].apply(lambda x:dic1[x] if x in dic1 else x)\n",
    "#     print(city.shape)\n",
    "#     print(city['城市'].nunique())\n",
    "    \n",
    "    vehicle=vehicle.merge(city,on=['城市'],how='left')\n",
    "\n",
    "    fill_dic1={'省份':'未知','城市':'未知','城市级别':'未知'}\n",
    "    for col in fill_dic1:\n",
    "        vehicle[col]=vehicle[col].fillna(fill_dic1[col])\n",
    "        \n",
    "    car_dict={'高档':4, '中高档':3, '中低档':2, '低档':1}\n",
    "    vehicle['车型档次']=vehicle['车型档次'].map(car_dict)\n",
    "\n",
    "    city_dict={'三线城市':4, '一线城市':7, '二线发达城市':6, '二线城市':5,\n",
    "         '四线城市':3, '六线城市':1, '五线城市':2,'未知':0}\n",
    "    vehicle['城市级别']=vehicle['城市级别'].map(city_dict)\n",
    "    \n",
    "    return vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.检查vin数量\n",
      "(850310, 33)\n",
      "850310\n",
      "2.去掉又没有进店数据又没有购车时间的\n",
      "(0, 33)\n",
      "0\n",
      "3.检查最终vin人数:\n",
      "(850310, 33)\n",
      "850310\n",
      "4.加入分类情况:\n",
      "(804143, 5)\n",
      "804143\n",
      "##########################开始补充缺失值#########################\n",
      "1.一级车系和车型档次\n",
      "2.vin相关属性\n",
      "3.车型代码\n",
      "4.车子相关属性\n",
      "########################匹配常去经销商的省份\\城市\\城市级别信息###############\n",
      "查看缺失的字段:\n",
      "       字段名    缺失值     缺失值占比\n",
      "0    新购车时间  46167  0.054294\n",
      "1    常去经销商  45777  0.053836\n",
      "2  第一次修理日期  45777  0.053836\n"
     ]
    }
   ],
   "source": [
    "vehicle1=update_vehicle(datap,vehicle,changqu,new_buy,fin_zhudan_df)\n",
    "mis1,mis2=get_miss_cols(vehicle1)\n",
    "print('查看缺失的字段:')\n",
    "print(mis2.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle1.to_pickle(savep+'vehicle_info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>3.得到yanghu_yisun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########第一批数据,加载零件信息表#############\n",
      "(22884328, 9)\n",
      "['经销商代码', '结算单号', '零件代码', '零件名称', '委托书号', '零件数量', 'VIN', '修理日期', '公里数']\n",
      "      经销商代码          结算单号         零件代码                   零件名称         委托书号  \\\n",
      "0  74301010  BO1401020073   06J115403K      机滤(途观/New Passat)  201401-0090   \n",
      "1  74301010  BO1401020073   1KD129620B    空气滤芯(途观/New Passat)  201401-0090   \n",
      "2  74301010  BO1401020073   1KD819653A  空调滤芯 途观/途安/New passat  201401-0090   \n",
      "3  74301010  BO1401020073  GCB052195Z2                壳牌全合成机油  201401-0090   \n",
      "4  74301010  BO1401020073  GCN060164Z1               车窗用清洁玻璃水  201401-0090   \n",
      "\n",
      "   零件数量                VIN       修理日期      公里数  \n",
      "0   1.0  LSVUD65N0A2870394 2014-01-02  36418.0  \n",
      "1   1.0  LSVUD65N0A2870394 2014-01-02  36418.0  \n",
      "2   1.0  LSVUD65N0A2870394 2014-01-02  36418.0  \n",
      "3   5.0  LSVUD65N0A2870394 2014-01-02  36418.0  \n",
      "4   2.0  LSVUD65N0A2870394 2014-01-02  36418.0  \n"
     ]
    }
   ],
   "source": [
    "print('###########第一批数据,加载零件信息表#############')\n",
    "lingjian1=pd.read_pickle(new_datap+'%s_维修零件信息%s.pickle'%(filename,num))\n",
    "    \n",
    "cols=['经销商代码', '结算单号', '零件代码', '零件名称', '委托书号', '零件数量']\n",
    "lingjian1=lingjian1[cols].drop_duplicates().reset_index(drop=True)\n",
    "lingjian1['经销商代码']=lingjian1['经销商代码'].astype(int).astype(str)\n",
    "\n",
    "zhudan_pipei1=pd.read_pickle(savep+'zhudan_pipei_lingjian_15selected.pkl')\n",
    "zhudan_pipei1['经销商代码']=zhudan_pipei1['经销商代码'].astype(int).astype(str)\n",
    "dt1=lingjian1.merge(zhudan_pipei1,on=['经销商代码','委托书号','结算单号'],how='left')\n",
    "dt1=dt1[dt1['修理日期'].notnull()]\n",
    "print(dt1.shape)\n",
    "print(dt1.columns.tolist())\n",
    "print(dt1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1['零件代码'] = dt1['零件代码'].apply(lambda x: str(x).replace(' ',''))\n",
    "dt1['零件代码'] = dt1['零件代码'].apply(lambda x: str(x).replace('#',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1['修理日期']=pd.to_datetime(dt1['修理日期'])\n",
    "dt1['零件数量']=dt1['零件数量'].astype(float)\n",
    "dt1['零件代码'] = dt1['零件代码'].apply(lambda x: str(x).replace(' ',''))\n",
    "dt1['零件代码'] = dt1['零件代码'].apply(lambda x: str(x).replace('#',''))\n",
    "dt1['零件名称'] = dt1['零件名称'].apply(str)\n",
    "dt1=dt1.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22453789, 9)\n",
      "      经销商代码          结算单号         零件代码                   零件名称         委托书号  \\\n",
      "0  74301010  BO1401020073   06J115403K      机滤(途观/New Passat)  201401-0090   \n",
      "1  74301010  BO1401020073   1KD129620B    空气滤芯(途观/New Passat)  201401-0090   \n",
      "2  74301010  BO1401020073   1KD819653A  空调滤芯 途观/途安/New passat  201401-0090   \n",
      "3  74301010  BO1401020073  GCB052195Z2                壳牌全合成机油  201401-0090   \n",
      "4  74301010  BO1401020073  GCN060164Z1               车窗用清洁玻璃水  201401-0090   \n",
      "\n",
      "                 VIN       修理日期      公里数  配件数量  \n",
      "0  LSVUD65N0A2870394 2014-01-02  36418.0   1.0  \n",
      "1  LSVUD65N0A2870394 2014-01-02  36418.0   1.0  \n",
      "2  LSVUD65N0A2870394 2014-01-02  36418.0   1.0  \n",
      "3  LSVUD65N0A2870394 2014-01-02  36418.0   5.0  \n",
      "4  LSVUD65N0A2870394 2014-01-02  36418.0   2.0  \n"
     ]
    }
   ],
   "source": [
    "tmp=dt1.groupby(['VIN','修理日期','零件代码'])['零件数量'].sum().reset_index()\n",
    "del dt1['零件数量']\n",
    "dt1=dt1.merge(tmp,on=['VIN','修理日期','零件代码'],how='left')\n",
    "dt1=dt1.loc[dt1['零件数量']>0]\n",
    "dt1.rename(columns = {'零件数量':'配件数量'},inplace = True)\n",
    "dt1['配件数量'] = dt1['配件数量'].astype('float')\n",
    "print(dt1.shape)\n",
    "print(dt1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    品种         零件号\n",
      "0  制动液   B000600A3\n",
      "1  制动液  B000750M1V\n",
      "2  制动液  B000750M3V\n",
      "3  制动液  B000750M6V\n",
      "4  制动液  B000750M7V\n"
     ]
    }
   ],
   "source": [
    "pro_code = pd.read_excel(datap+'常用保养养护易损件界定-众调-20200203.xlsx',sheet_name='编号清单-保养养护易损件')\n",
    "pro_code.loc[pro_code['常用配附件分类'] == '楔形皮带（发电机）','常用配附件分类'] = '楔形皮带'\n",
    "pro_code.loc[pro_code['常用配附件分类'] == '正时皮带/链条','常用配附件分类'] = '正时皮带'\n",
    "pro_code.loc[pro_code['常用配附件分类'] == '防冻液/冷却液','常用配附件分类'] = '防冻液'\n",
    "pro_code.loc[pro_code['常用配附件分类'] == '其他（绿色养护等）','常用配附件分类'] = '绿色养护'\n",
    "\n",
    "pro_code = pro_code[['常用配附件分类','配附件代码（去空格，去#）']]\n",
    "pro_code.rename(columns = {'常用配附件分类':'品种','配附件代码（去空格，去#）':'零件号'},inplace = True)\n",
    "pro_code = pro_code.drop_duplicates()\n",
    "print(pro_code.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11261553, 8)\n"
     ]
    }
   ],
   "source": [
    "dtt = pd.merge(dt1,pro_code, left_on = '零件代码',right_on = '零件号',how = 'left')\n",
    "dtt = dtt[~pd.isnull(dtt['品种'])]\n",
    "cols=['VIN', '修理日期', '经销商代码', '公里数', '零件代码', '零件名称', '品种', '配件数量']\n",
    "dtt=dtt[cols].drop_duplicates().rename(columns={'品种':'find'}).reset_index(drop=True)\n",
    "print(dtt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt.to_pickle(savep+'yanghu_yisun_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 36.30233661731084\n"
     ]
    }
   ],
   "source": [
    "print('run time:',(time.time()-s1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
